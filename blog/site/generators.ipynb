{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Methods, iterables, and generators for reading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all need to open, close, and save data to files using Python. Loading a file always involves reading the lines in the file, and possibly doing some processing on each line. An example file $\\textbf{test_data.txt}$ contains 1,000,000 rows (lines) and 3 columns separated by an empty space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"generators/test_data.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Python Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_loader(fn):\n",
    "    with open(fn) as fid:\n",
    "        lines = fid.readlines() # Read in lines until reaching EOF\n",
    "        lines = [line.strip(\"\\n\").split(\" \")[-1] for line in lines] # Process each line\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for processed_line in method_loader(fn):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire file was read into memory with the .readlines() call, before any line processing was performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files like this shouldn't be a problem for file sizes up to ~1G. But sometimes we have no choice and have to work with large files (sometimes hundreds of gigs). As a result the readlines operation can take a very long time. Furthermore, if the file is too large to load into memory, python will throw the error __MemoryError__ and your program will terminate *with error*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We frequently encounter large datafiles at NCAR. What can we do about it? \n",
    "\n",
    "Reading and processing one line at a time would solve this problem. We could even process an \"infinitely\" large file, which means any file that's too large to load fully into memory.\n",
    "\n",
    "This kind of file reading is called __lazy__ reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Python Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a special tool in the python toolbox that easily enables lazy reading called a generator. The generator object is built on top of python's Iterator object class, but I will cover them in reverse below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loader(fn):\n",
    "    with open(fn, \"r\") as fid:\n",
    "        for line in fid:\n",
    "            yield line.strip(\"\\n\").split(\" \")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've replaced the return with something new named $\\color{green}{\\textbf{yield}}$. This chunk of code looks similar to the method_loader!\n",
    "\n",
    "Test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for processed_line in generator_loader(fn):\n",
    "    print(processed_line)\n",
    "    break # Stop early, I don't need to print 1,000,000 lines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It behaves similarly when in use as compared to the method variant presented above. The big difference is that the generator version is more memory efficient because, through $\\color{green}{\\textbf{yield}}$, lines are read into memory one at a time, returned, released, ..., until reaching the end of the file (EOF). \n",
    "\n",
    "That is to say $\\color{green}{\\textbf{yield}}$ returns more than once, whereas $\\color{green}{\\textbf{return}}$ in a method signals the end (in terms of memory usage, as it is freed and the method is exited). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators work nicely with serialized data ... you may have __*dumped*__ data using the pickle library before. The pickle library allows you to do that for the entire file, all in one go, or line-by-line as the example below illustrates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_pkl = \"generators/test_data.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_pickle(data, fn):\n",
    "    with open(fn, \"wb\") as fid:\n",
    "        for line in data:\n",
    "            pickle.dump(line, fid) # Iteration over .dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_pickle(\n",
    "    method_loader(fn),\n",
    "    fn_pkl\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here will assume that we do not know how many lines are in our serialized data dump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pickle(fn):\n",
    "    with open(fn, \"rb\") as fid:\n",
    "        while True: # Keep looping with while.\n",
    "            yield pickle.load(fid) # Iteration over .load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the $\\color{green}{\\textbf{while True}}$ clause will keep looping over the call to load pickled data until we reach the end of the file. \n",
    "\n",
    "Test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2de8c1965edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mload_from_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-45015fa1bf7e>\u001b[0m in \u001b[0;36mload_from_pickle\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Keep looping with while.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Iteration over .load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "for row in load_from_pickle(fn_pkl):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It failed! \n",
    "\n",
    "There must still be a signal that can be used to stop the geneartor from yielding the next line when it does not exist. \n",
    "\n",
    "Note that python threw an end-of-file error $\\color{red}{\\textbf{EOFError}}$. We can catch that and use it to exit the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pickle(fn):\n",
    "    with open(fn, \"rb\") as fid:\n",
    "        try:\n",
    "            while True: # We do not necessarily know how many lines are in fn\n",
    "                yield pickle.load(fid)               \n",
    "        except EOFError:\n",
    "            pass # Do nothing and leave read_from_pickle without error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it will run without error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in load_from_pickle(fn_pkl):\n",
    "    continue\n",
    "    \n",
    "# Finishes without error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is rather clunky! Now we have to do *exception handling* (gasp). You might be wondering what good are python generators at helping us to simplify memory usage when this style of coding makes the workflow more complex. We could have relied on python's Iterator objects (covered next), to do lazy reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunatly, there is a generalized version of yield, $\\color{green}{\\textbf{yield from}}$ for these siuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pickle(fn):\n",
    "    with open(fn, \"rb\") as fid:\n",
    "        yield from pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in load_from_pickle(fn_pkl):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finishes without error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, generators allow us to write simple code that helps to simplfy memory usage when working with large data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Python Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generators were introduced, one relied on a python __Iterator__ object to produce lazy readers. Iterable classes are not too difficult to write, but they have dependencies, in particular, they must contain the $\\color{blue}{\\textbf{__iter__}}$ and $\\color{blue}{\\textbf{__next__}}$ \"thunder\" methods. \n",
    "\n",
    "A simple example with our serialized (pickled) data from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class read_from_pickle_iterable:\n",
    "    \n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "        self.fid = open(self.fn, \"rb\")\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            return pickle.load(self.fid)\n",
    "        except EOFError:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thunder method $\\color{blue}{\\textbf{__iter__}}$ returns the object itself (through self!), while $\\color{blue}{\\textbf{__next__}}$ is used to return the result of the .load call on the opened file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpi = read_from_pickle_iterable(fn_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Iterator's $\\color{blue}{\\textbf{__next__}}$ functionality, we then grab the lines from the file one-by-one without opening the entire file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-1e1bfab26979>\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d7c5bd59b55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Use next like this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-1e1bfab26979>\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    next(rfpi) # Use next like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which dies as intended when the $\\color{red}{\\textbf{EOFError}}$ and the $\\color{red}{\\textbf{StopException}}$ is thrown using the $\\color{green}{\\textbf{raise}}$ clause. When the iterator object is iterated out, for example rolled out in a for loop (or by list(), enumerate(), etc) it will exit without error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in read_from_pickle_iterable(fn_pkl):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why even have generators when there are already iterators?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is because generators are more compact and easier to write, as you do not have to explicitly sub-class them with the $\\color{blue}{\\textbf{__iter__}}$ and $\\color{blue}{\\textbf{__next__}}$. That's taken care of under-the-hood with the generator class. But the converse is not true: iterables do not have the yield capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When should I use a generator rather than a method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of scenerios, in addition to data loading! Note that in the first method example above, a list was returned. Do you need all elements of the list, all at the same time? If the answer is no, then you want to try to use a generator if that file is large in size!\n",
    "\n",
    "With generators one tries to balance the time spent performing operations with/on the data with memory utilization. Using them will often be determined by how your program is designed to run and utilize resources. If you are presented with a significant memory bottleneck, generators are very often the way to go. However if your program does not have said memory issue, using a generator might result in the program running significantly slower. \n",
    "\n",
    "As you use generators more and more in your work-flow, you will learn to apply them when they are needed and when to avoid them when they do not offer any benefit over using methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to email me (John Schreck, schreck@ucar.edu) with any questions / mistakes / whatever!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
