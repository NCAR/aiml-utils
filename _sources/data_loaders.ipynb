{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loaders for ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 1 of this blog, we looked at python methods, generators, and iterators for lazy data reading. \n",
    "\n",
    "In this blog post, we will combine these tools and build something a little more involved: Effecient data objects for preparation and data ingestion into ML models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the holodec data (as of Oct 12, 2020), which contains large hologram images and numerical data accompaning each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holodecml.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_datasets(path_data, num_particles, split, output_cols, subset):\n",
    "    ds = open_dataset(path_data, num_particles, split)\n",
    "    if subset:\n",
    "        ix = int(subset * ds['image'].shape[0])\n",
    "        inputs = ds['image'][:ix].values\n",
    "        outputs = ds[output_cols].to_dataframe()\n",
    "        outputs = outputs[outputs[\"hid\"] < (ix+1)]\n",
    "    else:\n",
    "        inputs = ds[\"image\"].values\n",
    "        outputs = ds[output_cols].to_dataframe()    \n",
    "    ds.close()\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/\"\n",
    "num_particles = \"multi\"\n",
    "split = 'train'\n",
    "subset = False\n",
    "output_cols = [\"x\", \"y\", \"z\", \"d\", \"hid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "inputs, outputs = load_raw_datasets(path_data, num_particles, split, output_cols, subset)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is pretty large, not large enough to cause memory overflow but its a big one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first write a lazy reader that returns the same things as the above method, but one row at a time. Then we will utilize special Iterable objects from the torch, tensorflow, and keras libraries that will enable multiprocessing with multiple workers, batching, and other transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch.utils.data.Dataset and tensorflow.keras.utils.Sequence objects are nearly identical to each other in that both require a custom Reader to contain at minumum the __len__ and __getitem__ (thunder) methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HologramReader(Dataset): # Sequence\n",
    "    \n",
    "    'Generates data for Keras/Tensorflow/Torch environments'\n",
    "    \n",
    "    def __init__(self, \n",
    "                 path_data, \n",
    "                 num_particles, \n",
    "                 split, \n",
    "                 output_cols, \n",
    "                 subset, \n",
    "                 maxnum_particles = 100):\n",
    "        \n",
    "        'Initialization'\n",
    "        self.ds = open_dataset(path_data, num_particles, split)\n",
    "        self.output_cols = [x for x in output_cols if x != 'hid']        \n",
    "        self.hologram_numbers = list(range(len(self.ds.hologram_number.values)))\n",
    "        self.maxnum_particles = maxnum_particles\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.hologram_numbers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        'Return one row of data'\n",
    "        \n",
    "        # Select one \"row\" from the dataset\n",
    "        hologram = self.hologram_numbers[idx]\n",
    "\n",
    "        x_out = self.ds[\"image\"][hologram].values\n",
    "        y_out = np.zeros((\n",
    "            self.maxnum_particles if self.maxnum_particles else self.num_particles, \n",
    "            len(self.output_cols)\n",
    "        ))\n",
    "        particles = np.where(self.ds[\"hid\"] == hologram + 1)[0]\n",
    "        for l, p in enumerate(particles):\n",
    "            for m, col in enumerate(self.output_cols):\n",
    "                y_out[l, m] = self.ds[col].values[p]\n",
    "\n",
    "        return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reader = HologramReader(path_data, num_particles, split, output_cols, subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method __getitem__ is used to select whichever hologram we want (take the one labeled 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data_reader.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a quick plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the torch/keras Reader, we wrap a torch DataLoader object around it to enable iterative batching as well as multiprocessing capabilities (among other options). As noted, the DataLoader object requires that the Reader class contains the __len__ and __getitem__ thunder methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = DataLoader(\n",
    "    data_reader,\n",
    "    num_workers = 8,\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in data_iterator:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataLoader object will take care of creating independent workers that each will load the Reader and put the row data onto a queue. The first few calls to data_iterator will be slow as the workers have to be initialized before queues start to fill up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras\n",
    "\n",
    "When using Keras, all we have to do is swap HologramReader(Dataset) for HologramReader(Sequence) and make no other changes. We could just skip the inheritance and specify the output type (torch tensor versus numpy tensor) upon return.\n",
    "\n",
    "In older Keras versions, the Reader would be fed into the Model.fit_generator method, which allowed one to toggle the number of workers. The important bit about the Sequence object is that it is thread-safe, meaning the workers spawned will not duplicate data chunks (this isn't a major problem when shuffling the data).\n",
    "\n",
    "The torch DataLoader came with shuffle capability (by initializing a random order using the __len__ method), whereas in the Sequence object, shuffle functionality (and whatever else you want) can be enabled by adding a method typically called \"on_epoch_end\" that will shuffle after some number of data points have been returned. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensorflow\n",
    "\n",
    "But, since the Sequence object was recently deprecated in favor of Tensorflow's data objects, we will proceed by setting up one of those. We only have to make a few adjustments to the above Readers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFHologramReader: \n",
    "    \n",
    "    'Generates data for Keras/Tensorflow/Torch environments'\n",
    "    \n",
    "    def __init__(self, \n",
    "                 path_data, \n",
    "                 num_particles, \n",
    "                 split, \n",
    "                 output_cols, \n",
    "                 subset, \n",
    "                 maxnum_particles = 100):\n",
    "        \n",
    "        'Initialization'\n",
    "        self.ds = open_dataset(path_data, num_particles, split)\n",
    "        self.output_cols = [x for x in output_cols if x != 'hid']        \n",
    "        self.hologram_numbers = list(range(len(self.ds.hologram_number.values)))\n",
    "        self.maxnum_particles = maxnum_particles\n",
    "    \n",
    "    def __call__(self):\n",
    "        'Return one row of data'\n",
    "        for k, hologram in enumerate(self.hologram_numbers):\n",
    "            # Select one \"row\" from the dataset\n",
    "            x_out = self.ds[\"image\"][hologram].values\n",
    "            y_out = np.zeros((\n",
    "                self.maxnum_particles if self.maxnum_particles else self.num_particles, \n",
    "                len(self.output_cols)\n",
    "            ))\n",
    "            particles = np.where(self.ds[\"hid\"] == hologram + 1)[0]\n",
    "            for l, p in enumerate(particles):\n",
    "                for m, col in enumerate(self.output_cols):\n",
    "                    y_out[l, m] = self.ds[col].values[p]\n",
    "\n",
    "            yield tf.convert_to_tensor(x_out), tf.convert_to_tensor(y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this Reader's __call__ is a generator, whereas before we used a method.\n",
    "\n",
    "Calling and using the reader is the same as before. First, initialize an instance by setting the input variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_generator = TFHologramReader(\n",
    "    path_data, num_particles, split, output_cols, subset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we wrap Tensorflow's Dataset object around the generator, using the from_generator method within the Dataset object, and setting the tensor types explictly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_iterator = tf.data.Dataset.from_generator(\n",
    "    tf_data_generator, \n",
    "    (tf.dtypes.float32, tf.dtypes.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the batch size can be done by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_iterator = tf_data_iterator.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling is a little more complex. Since a generator is in play, a memory buffer of size buffer_size will be created and rows put into it. Then, batches are selected from it and returned. Note that there will be a delay in the begining as the buffer has to fill up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_iterator = tf_data_iterator.shuffle(buffer_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get true random sampling, the buffer size would need to be the size of the data set.\n",
    "\n",
    "In practice, one should shuffle the hologram numbers list in the TFReader upon initialization since they are available, similar to what needed to be done when using the keras Sequence object. For the sake of illustration we use tensorflows method for shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in tf_data_iterator:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of workers can be set when training the model through the .fit() super-class (which contains an machinery for rolling out the Reader and feeding the batches it into the model):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model.fit(\n",
    "    tf_data_iterator,\n",
    "    ...,\n",
    "    use_multiprocessing = True, \n",
    "    workers = 8,\n",
    "    max_queue_size = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could use any of these approaches with either ML language, though the torch and tensorflow versions are superior to the now-deparecated Sequence. The later is true in the case of running with one worker at a time. Enabling multiprocessing on your own with Tensorflow stuff is tricky! You need to \"shard\" the data into chunks first, then each chunk is shipped off to a worker. The Torch iterator object does all of this more, under the hood. \n",
    "\n",
    "These special iterator objects contain many other features not covered here, so be sure to check out the documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Dataset: https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "Torch Dataset: https://pytorch.org/docs/stable/data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
