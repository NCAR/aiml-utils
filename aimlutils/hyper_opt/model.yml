log: 'test'
type: "encoder-vae"

data:
  path_data: "/glade/scratch/schreck/holodec/"
  num_particles: "50-100"
  maxnum_particles: 100
  output_cols: ["x", "y", "z", "d", "binary"]
  subset: False
  
transforms:
  #RandomVerticalFlip: False
  #RandomHorizontalFlip: False
  Rescale: 600
  Normalize: 'norm'
  ToTensor: True

iterator:
  num_workers: 8
  batch_size: 32
  pin_memory: True
  shuffle: True
  
model:
  image_channels: 1
  hidden_dims: [3, 94, 141, 471, 425, 1122]
  z_dim: 1277
  dense_hidden_dims: [1000]
  dense_dropouts: [0.0]
  tasks: ["x", "y", "z", "d", "binary"]
  pretrained_model: "pretrained/pretrained.pt"

optimizer:
  type: "lookahead-diffgrad"
  lr: 0.000631
  weight_decay: 0.0

callbacks:
  MetricsLogger:
    path_save: "test"
    reload: False
  EarlyStopping:
    patience: 5
    verbose: True
    path_save: "test/checkpoint.pt"
  ExponentialLR:
    gamma: 0.95
    
#   ReduceLROnPlateau: 
#     mode: "min"
#     factor: 0.2
#     patience: 1
#     min_lr: 0.0000000001
#     verbose: True

trainer:
  start_epoch: 0
  epochs: 1
  clip: 1.0
  alpha: 1.0
  beta: 0.1
  path_save: "test"
  test_image: "test/image_600.pkl"
  
# optuna:
#   n_trials: 500
#   save_path: 'test'
#   parameters:
#     num_dense:
#       type: "int"
#       settings:
#           name: "num_dense"
#           low: 0
#           high: 10
#     dense_hidden_dim1:
#       type: "int"
#       settings:
#         name: "dense_hidden_dim1"
#         low: 10
#         high: 10000
#     dense_hidden_dim2:
#       type: "int"
#       settings:
#         name: "dense_hidden_dim2"
#         low: 10
#         high: 5000
#     dr1:
#       type: "float"
#       settings:
#         name: "dr1"
#         low: 0.0
#         high: 0.5
#     dr2:
#       type: "float"
#       settings:
#         name: "dr1"
#         low: 0.0
#         high: 0.5
#     trainer:alpha:
#       type: "float"
#       settings:
#         name: "alpha"
#         low: 0.001
#         high: 1.0
#     trainer:beta:
#       type: "float"
#       settings:
#         name: "beta"
#         low: 0.001
#         high: 1.0
#     optimizer:lr:
#       type: "loguniform"
#       settings:
#         name: "lr"
#         low: 0.0000001
#         high: 0.01
#     optimizer:weight_decay:
#       type: "loguniform"
#       settings:
#         name: "weight_decay"
#         low: 0.00000001
#         high: 0.1